# Vision Transformer Implementation from Scratch!

## Introduction
Welcome to the Vision Transformer from Scratch! GitHub repository! This project, developed by Aman Bisht, is a detailed implementation of the Vision Transformer (ViT), a groundbreaking architecture that has revolutionized the field of computer vision. Unlike traditional convolutional neural networks, ViT relies on the self-attention mechanism to process images, offering a novel approach to understanding visual data. This repository not only includes the complete code for the Vision Transformer but also provides comprehensive explanations of each part of the code, the input processing, and the output generation mechanisms.

## Project Description
I have worked on implementing the Vision Transformer from scratch, where I have written every explanation from scratch to ensure everything is clear about how exactly the Vision Transformer works.

## Features
- **Detailed Code Comments**: Each section of the code is meticulously commented on to explain the functionality and logic, making it accessible for learners and researchers alike.
- **Step-by-Step Explanation**: The repository includes a thorough explanation of how the Vision Transformer processes input images and produces outputs, demystifying the inner workings of this complex model.
- **Customizable Architecture**: Users can easily modify the model parameters (e.g., number of layers, attention heads, etc.) to suit different computational constraints and dataset requirements.
  
## Installation
To use this Vision Transformer implementation just upload the file on Google Colab and you are good to go!!

## Acknowledgments
- Deep Findr YouTube channel: https://www.youtube.com/watch?v=j3VNqtJUoz0&t=510s&ab_channel=DeepFindr

## Contact
For any queries or discussions regarding the project, feel free to reach out to bishtaman0774@gmail.com.
